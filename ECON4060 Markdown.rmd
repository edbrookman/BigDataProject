---
title: "Big Data: Group Summative Project"
output: word_document
date: "`format(Sys.time(), '%d %B %Y')"
---


```{r setup, include= FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/james/OneDrive - The University of Nottingham/Documents/Notts/Big data/Real project")
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)
```
```{r data cleaning, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
library(quantmod)  
library(ggcorrplot)
library(caret)
library(yfR)
library(rpart)
library(randomForest)
library(rpart.plot)
library(gbm)
library(glmnet)
library(readxl)
library(zoo)
library(vip)

# Obtain stock price data from Yahoo Finance

# BVSP

first_date <- '2019-01-01'
last_date <- '2024-03-20'

BVSP_data <- yf_get(tickers =  "^BVSP", 
                   first_date = first_date, 
                   last_date = last_date)

range(BVSP_data$ref_date)

write.csv(BVSP_data,  "BVSP_data", row.names = FALSE)

# FTAS

FTAS_data <- yf_get(tickers = "^FTAS",
                  first_date = first_date, 
                  last_date = last_date)

range(FTAS_data$ref_date)

write.csv(FTAS_data,  "FTAS_data.csv", row.names = FALSE)

# First, considering data from 2023 onward (shorter term)

BVSP_s <- BVSP_data %>% 
    dplyr::select(ref_date, price_open, price_close, price_high, price_low, price_adjusted, volume,ret_adjusted_prices)
BVSP_s$volume= log(BVSP_s$volume)
colnames(BVSP_s) =c("date", "open"  , "close" , "high", "low", "price", "logvolume", "return") 
range(BVSP_s$date)

BVSP_s <- subset(BVSP_s, !is.infinite(logvolume))

FTAS_s <- FTAS_data %>%   dplyr::select(ref_date, price_open, price_close, price_high, price_low, price_adjusted, volume,ret_adjusted_prices)
FTAS_s$volume= log(FTAS_s$volume)
colnames(FTAS_s) =c("date", "open"  , "close" , "high", "low", "price", "logvolume", "return") 
head(FTAS_s)
range(FTAS_s$date)


#compute direction variable based on daily returns

BVSP_s$direction <- as.factor(ifelse(BVSP_s$return<0,"DOWN","UP"))
FTAS_s$direction <- as.factor(ifelse(FTAS_s$return<0,"DOWN","UP"))

# next day's direction
BVSP_s$direction.1 <- dplyr::lead(BVSP_s$direction,1,order_by=BVSP_s$date)
FTAS_s$direction.1 <- dplyr::lead(FTAS_s$direction,1,order_by=FTAS_s$date)

#compute a different direction variable based on intraday returns
BVSP_s$intraday <- log(BVSP_s$close) - log(BVSP_s$open) 
FTAS_s$intraday <- log(FTAS_s$close) - log(FTAS_s$open)

BVSP_s$dirintra<- as.factor(ifelse(BVSP_s$intraday < -0.0075,"LARGE_DOWN", 
                                   ifelse(BVSP_s$intraday > -0.0075 & BVSP_s$intraday <=0, "SMALL_DOWN", 
                                          ifelse(BVSP_s$intraday > 0 & BVSP_s$intraday <0.0075, "SMALL_UP","LARGE_UP"))))

FTAS_s$dirintra<- as.factor(ifelse(FTAS_s$intraday < -0.0075,"LARGE_DOWN", 
                                   ifelse(FTAS_s$intraday > -0.0075 & FTAS_s$intraday <=0, "SMALL_DOWN", 
                                          ifelse(FTAS_s$intraday > 0 & FTAS_s$intraday <0.0075, "SMALL_UP","LARGE_UP"))))

BVSP_s$direction.2 <-lead(BVSP_s$dirintra,1,order_by=BVSP_s$date)
FTAS_s$direction.2 <-lead(FTAS_s$dirintra,1,order_by=FTAS_s$date)


### External indicators ----------------------------------------------------------------------------------

## Crude oil price
OIL <- yf_get(tickers = "CL=F",
              first_date = first_date, 
              last_date = last_date)  
OIL <- OIL %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, oil_price = price_close)

## Exchange rates

# UK GBP - EUR/USD
GBPUSD <- yf_get(tickers =  "GBPUSD=X", 
               first_date = first_date, 
               last_date = last_date)

GBPUSD <- GBPUSD %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, GBPUSD = price_close)

GBPEUR <- yf_get(tickers =  "GBPEUR=X", 
                 first_date = first_date, 
                 last_date = last_date)

GBPEUR <- GBPEUR %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, GBPEUR = price_close)

# Brazilian Real - EUR/USD

BRLUSD <- yf_get(tickers =  "BRLUSD=X", 
                 first_date = first_date, 
                 last_date = last_date)

BRLUSD <- BRLUSD %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, BRLUSD = price_close)

BRLEUR <- yf_get(tickers =  "BRLEUR=X", 
                 first_date = first_date, 
                 last_date = last_date)

BRLEUR <- BRLEUR %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, BRLEUR = price_close)

## Interest rates

UKBOND <- read_csv("UK_1yr_bond.csv") %>% dplyr::select(Date, Price) %>%
  rename(date = Date, uk_bond = Price)

UKBOND$date <- mdy(UKBOND$date)

BRAZILBOND <- read_csv("Brazil_1yr_bond.csv") %>% dplyr::select(Date, Price) %>%
  rename(date = Date, brazil_bond = Price)

BRAZILBOND$date <- mdy(BRAZILBOND$date)


## Commodity prices

corn <- yf_get(tickers = "ZC=F",
               first_date = first_date,
               last_date = last_date)

sugar <- yf_get(tickers = "SB=F",
                first_date = first_date,
                last_date = last_date)

gold <- yf_get(tickers = "GC=F",
               first_date = first_date,
               last_date = last_date)

corn <- corn %>% dplyr::select(ref_date, price_close) %>% 
  rename(date = ref_date, corn_price = price_close)

sugar <- sugar %>% dplyr::select(ref_date, price_close)%>% 
  rename(date = ref_date, sugar_price = price_close)

gold <- gold %>% dplyr::select(ref_date, price_close) %>% 
  rename(date = ref_date, gold_price = price_close)

commodities <- merge(corn, sugar, by = "date", all = TRUE) %>%
  merge(gold, by = "date", all = TRUE)

## Economic Policy Uncertainty

EPU <- read.csv("UK_Daily_Policy_Data.csv") 
EPU$date <- as.Date(EPU$date, format = "%d %m %Y")

## Neighbours

brazil_neighbour <- yf_get(tickers =  "EWZ", 
                           first_date = first_date,
                           last_date = last_date)  #measure of the exchange traded funds in Brazil- like a stock but dont involve actual ownership of securities. its a pre-defined basket of goods in the brazilian economy 

brazil_neighbour <- brazil_neighbour %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, brazil_neighbour = price_close)

uk_neighbour <- yf_get(tickers =  "^STOXX", 
                       first_date = first_date,
                       last_date = last_date) #Measure of Europe

uk_neighbour <- uk_neighbour %>% dplyr::select(ref_date, price_close) %>%
  rename(date = ref_date, uk_neighbour = price_close)

## Carbon and electricity prices

carbon_prices <- read_csv("carbon price data.csv") #2005 to oct 2023
electricity_prices <- read_excel("electricity prices data.xlsx") #2020 to 2024

#clean data                                                                                 
carbon_prices <- carbon_prices %>% dplyr::select(date, eu_price, nz_price, kor_price, uk_price)
carbon_prices$date <- dmy(carbon_prices$date)
carbon_prices <- carbon_prices %>% filter(carbon_prices$date >= first_date) %>%
  rename(eu_carbon_price = eu_price, nz_carbon_price = nz_price, kor_carbon_price = kor_price, uk_carbon_price = uk_price)


electricity_prices <- electricity_prices %>% rename(daily_elec_avg= "Daily average",`7day_elec_avg`= "7-day average", date = Date)
electricity_prices <- electricity_prices %>% filter(electricity_prices$date >= first_date)

## Natural Gas commodity prices
NGAS <- yf_get(tickers =  "NG=F", 
               first_date = first_date,
               last_date = last_date)

NGASdf <- NGAS %>% dplyr::select(ref_date, price_adjusted)
colnames(NGASdf) = c("date", "NGAS price")


## Temperature data

temperature_brazil <- read_csv("temp_data.csv") %>% dplyr::select(date, brazil_temp)
temperature_brazil$date <- dmy(temperature_brazil$date)

temperature_uk <- read_csv("temp_data.csv") %>% dplyr::select(date, uk_temp)
temperature_uk$date <- dmy(temperature_uk$date)


## Merge all external indicators together

external_indicators <- merge(commodities, EPU, by = "date", all = TRUE) %>%
  merge(OIL, by = "date", all = TRUE) %>%
  merge(GBPUSD, by = "date", all = TRUE) %>%
  merge(GBPEUR, by = "date", all = TRUE) %>%
  merge(BRLUSD, by = "date", all = TRUE) %>%
  merge(BRLEUR, by = "date", all = TRUE) %>%
  merge(UKBOND, by = "date", all = TRUE) %>%
  merge(BRAZILBOND, by = "date", all = TRUE) %>%
  merge(brazil_neighbour, by = "date", all = TRUE) %>%
  merge(uk_neighbour, by = "date", all = TRUE) %>%
  merge(carbon_prices, by = "date", all = TRUE) %>%
  merge(electricity_prices, by = "date", all = TRUE) %>%
  merge(NGASdf, by = "date", all = TRUE) %>%
  merge(temperature_brazil, by = "date", all = TRUE) %>%
  merge(temperature_uk, by = "date", all = TRUE)

  
### Technical indicators -----------------------------------------------------------------------------

library(TTR)

# DV Intermediate Oscillator
BVSP_s$DVI2 <- DVI(BVSP_s$price,n=2)
BVSP_s$DVI7 <- DVI(BVSP_s$price,n=7)
BVSP_s$DVI14 <- DVI(BVSP_s$price,n=14)
BVSP_s$DVI21 <- DVI(BVSP_s$price,n=21)

FTAS_s$DVI2 <- DVI(FTAS_s$price,n=2)
FTAS_s$DVI7 <- DVI(FTAS_s$price,n=7)
FTAS_s$DVI14 <- DVI(FTAS_s$price,n=14)
FTAS_s$DVI21 <- DVI(FTAS_s$price,n=21)

# Ultimate Oscillator
BVSP_s$UltOsc <- ultimateOscillator(BVSP_s[,c("high", "low", "close")])
FTAS_s$UltOsc <- ultimateOscillator(FTAS_s[,c("high", "low", "close")])

# Triple Smoothed Exponential Oscillator (TRIX)
BVSP_s$TRIX2 <- TRIX(BVSP_s$price,n=2)
BVSP_s$TRIX5 <- TRIX(BVSP_s$price,n=5)
BVSP_s$TRIX10 <- TRIX(BVSP_s$price,n=10)

FTAS_s$TRIX2 <- TRIX(FTAS_s$price,n=2)
FTAS_s$TRIX5 <- TRIX(FTAS_s$price,n=5)
FTAS_s$TRIX10 <- TRIX(FTAS_s$price,n=10)


# runSum (runFunctions)
BVSP_s$runSum <- runSum(BVSP_s$price,n=10, cumulative=FALSE)
BVSP_s$runMin <- runMin(BVSP_s$price,n=10, cumulative=FALSE)
BVSP_s$runMax <- runMax(BVSP_s$price,n=10, cumulative=FALSE)
BVSP_s$runMedian <- runMedian(BVSP_s$price,n=10, cumulative=FALSE)
BVSP_s$runVar <- runVar(BVSP_s$price, y=NULL, n=10, cumulative=FALSE)
BVSP_s$runSD <- runSD(BVSP_s$price,n=10, cumulative=FALSE)
BVSP_s$runMAD <- runMAD(BVSP_s$price, n=10, center=NULL, 
                        stat="median", constant=1.4826,
                        non.unique="mean", cumulative=FALSE)
BVSP_s$wilderSum <- wilderSum(BVSP_s$price,n=10)

FTAS_s$runSum <- runSum(FTAS_s$price,n=10, cumulative=FALSE)
FTAS_s$runMin <- runMin(FTAS_s$price,n=10, cumulative=FALSE)
FTAS_s$runMax <- runMax(FTAS_s$price,n=10, cumulative=FALSE)
FTAS_s$runMedian <- runMedian(FTAS_s$price,n=10, cumulative=FALSE)
FTAS_s$runVar <- runVar(FTAS_s$price, y=NULL, n=10, cumulative=FALSE)
FTAS_s$runSD <- runSD(FTAS_s$price,n=10, cumulative=FALSE)
FTAS_s$runMAD <- runMAD(FTAS_s$price, n=10, center=NULL, 
                        stat="median", constant=1.4826,
                        non.unique="mean", cumulative=FALSE)
FTAS_s$wilderSum <- wilderSum(FTAS_s$price,n=10)

# Bollinger Bands
BVSP_s$BBands2 <- BBands(BVSP_s$price, n=2)
BVSP_s$BBands5 <- BBands(BVSP_s$price, n=5)
BVSP_s$BBands10 <- BBands(BVSP_s$price, n=10)

FTAS_s$BBands2 <- BBands(FTAS_s$price, n=2)
FTAS_s$BBands5 <- BBands(FTAS_s$price, n=5)
FTAS_s$BBands10 <- BBands(FTAS_s$price, n=10)

# Aroon indicator
BVSP_s$aroon2 <- aroon(BVSP_s[,c("high", "low")], n=2)
BVSP_s$aroon5 <- aroon(BVSP_s[,c("high", "low")], n=5)
BVSP_s$aroon10 <- aroon(BVSP_s[,c("high", "low")], n=10)

FTAS_s$aroon2 <- aroon(FTAS_s[,c("high", "low")], n=2)
FTAS_s$aroon5 <- aroon(FTAS_s[,c("high", "low")], n=5)
FTAS_s$aroon10 <- aroon(FTAS_s[,c("high", "low")], n=10)

# Williams Accumulation/Distribution
BVSP_s$WilliamsAD <- williamsAD(BVSP_s[,c("high", "low", "close")])
FTAS_s$WilliamsAD <- williamsAD(FTAS_s[,c("high", "low", "close")])

# Trend Detection Index
BVSP_s$tdi10 <- TDI(BVSP_s$price, n=10)
BVSP_s$tdi20 <- TDI(BVSP_s$price, n=20)
BVSP_s$tdi30 <- TDI(BVSP_s$price, n=30)

FTAS_s$tdi10 <- TDI(FTAS_s$price, n=10)
FTAS_s$tdi20 <- TDI(FTAS_s$price, n=20)
FTAS_s$tdi30 <- TDI(FTAS_s$price, n=30)

# Chaikin Accumulation/ Distribution

BVSP_s$ChaikinAD <- chaikinAD(BVSP_s[,c("high", "low", "close")], BVSP_s[,"logvolume"])
FTAS_s$ChaikinAD <- chaikinAD(FTAS_s[,c("high", "low", "close")], FTAS_s[,"logvolume"])


# Know Sure Thing (KST) 
#For each day (week, month, etc.), the KST calculates the ROC
#over several periods.
#Those ROCs are smoothed using the given moving averages,
#then multiplied by their respective weighting values.
#The resulting values are summed for each day (month, week, etc.).
FTAS_s$kst <- KST(FTAS_s$price, roc_periods = c(10, 15, 20, 30),
                   sma_periods = c(10, 10, 10, 15),
                   ema_periods = c(10, 10, 10, 10),
                   signal_periods = 9)

BVSP_s$kst <- KST(BVSP_s$price, roc_periods = c(10, 15, 20, 30),
                sma_periods = c(10, 10, 10, 15),
                ema_periods = c(10, 10, 10, 10),
                signal_periods = 9)


#  Chande Momentum Oscillator (CMO)
#The CMO divides the total movement by the net movement
#([up - down] / [up + down]),
#where RSI divides the upward movement by the net movement (up / [up + down]).

FTAS_s$cmo <- CMO(FTAS_s$price, n = 14)

BVSP_s$cmo <- CMO(BVSP_s$price, n = 14)


#Chaikin Money Flow
FTAS_s$cmf <- CMF(FTAS_s[, c("high", "low", "close")],
                  FTAS_s[, c("logvolume")])

BVSP_s$cmf <- CMF(BVSP_s[, c("high", "low", "close")],
                  BVSP_s[, c("logvolume")])


# Donchian Channel

# The top line is the highest high of the past n periods.
# The bottom line is the lowest low of the past n periods.
# The middle line is the average of the top and bottom lines.

FTAS_s$donchianchannel20 <- DonchianChannel(FTAS_s[, c("high",
                                                         "low")],
                                             n = 20)
FTAS_s$donchianchannel10 <- DonchianChannel(FTAS_s[, c("high",
                                                         "low")],
                                             n = 10)


BVSP_s$donchianchannel20 <- DonchianChannel(BVSP_s[, c("high",
                                                   "low")],
                                          n = 20)
BVSP_s$donchianchannel10 <- DonchianChannel(BVSP_s[, c("high",
                                                   "low")],
                                          n = 10)


# Ehlers Correlation trend Indicator

#Ehler's Correlation Trend Indicator (CTI) measures the Spearman
#correlation of the
#price with the ideal trend line: a straight line with increasing slope

FTAS_s$EHcorrel <- CTI(FTAS_s$price, n = 10, slope = 1)

BVSP_s$EHcorrel <- CTI(BVSP_s$price, n = 10, slope = 1)

#True range
FTAS_s$tr <- TR(FTAS_s[,c("high","low", "close")])
BVSP_s$tr <- TR(BVSP_s[,c("high","low", "close")])


#Directional Movement Index
FTAS_s$dx <- ADX(FTAS_s[,c("high","low", "close")], n = 14)
BVSP_s$dx <- ADX(BVSP_s[,c("high","low", "close")], n = 14)


#Relative Strength index
FTAS_s$rsi3 <- RSI(FTAS_s$intraday, n = 3)
FTAS_s$rsi5 <- RSI(FTAS_s$intraday, n = 5)
FTAS_s$rsi10 <- RSI(FTAS_s$intraday, n = 10)
FTAS_s$rsi14 <- RSI(FTAS_s$intraday, n = 14)

BVSP_s$rsi3 <- RSI(BVSP_s$intraday, n = 3)
BVSP_s$rsi5 <- RSI(BVSP_s$intraday, n = 5)
BVSP_s$rsi10 <- RSI(BVSP_s$intraday, n = 10)
BVSP_s$rsi14 <- RSI(BVSP_s$intraday, n = 14)


#Commodity Channel Index

#CCI relates the current price and the average of price over n periods. 
#The CCI usually falls in a channel of -100 to 100.
#A basic CCI trading system is:
#Buy (sell) if CCI rises above 100 (falls below -100)
#and sell (buy) when it falls below 100 (rises above -100).

FTAS_s$cci3 <- CCI(FTAS_s[,c("high","low", "close")],n = 3)
FTAS_s$cci5 <- CCI(FTAS_s[,c("high","low", "close")],n = 5)

BVSP_s$cci3 <- CCI(BVSP_s[,c("high","low", "close")],n = 3)
BVSP_s$cci5 <- CCI(BVSP_s[,c("high","low", "close")],n = 5)

#Close location value

#The CLV will fall in a range of -1 to +1. If the CLV is +/-1,
#the close is at the high/low; if the CLV is 0, the close is
#directly between the high and low.

FTAS_s$clv <- CLV(FTAS_s[,c("high","low", "close")])

BVSP_s$clv <- CLV(BVSP_s[,c("high","low", "close")])

# Guppy Multiple Moving Averages
FTAS_s$GMMA <- GMMA(
  FTAS_s$price,
  short = c(3, 5, 8, 10, 12, 15),
  long = c(30, 35, 40, 45, 50, 60),
)

BVSP_s$GMMA <- GMMA(
  BVSP_s$price,
  short = c(3, 5, 8, 10, 12, 15),
  long = c(30, 35, 40, 45, 50, 60),
)

# Parabolic Stop-and-Reverse
FTAS_s$sar<- SAR(FTAS_s[,c("high","low")], accel = c(0.02, 0.2))
BVSP_s$sar<- SAR(BVSP_s[,c("high","low")], accel = c(0.02, 0.2))

# Signal to Noise Ratio
FTAS_s$snr<- SNR(FTAS_s[,c("high","low", "close")], n=5)
BVSP_s$snr<- SNR(BVSP_s[,c("high","low", "close")], n=5)

# MACD Oscillator
FTAS_s$macd  <- MACD( FTAS_s$price, 12, 26, 9, maType="EMA" )
BVSP_s$macd  <- MACD( BVSP_s$price, 12, 26, 9, maType="EMA" )

# Vertical Horizontal Filter
FTAS_s$vhf <- VHF(FTAS_s$price, n = 28)
BVSP_s$vhf <- VHF(BVSP_s$price, n = 28)

# Zig Zag
FTAS_s$zigzag <- ZigZag(FTAS_s[,c("high","low")], change = 10, percent = TRUE, retrace = FALSE, lastExtreme = TRUE)
BVSP_s$zigzag <- ZigZag(BVSP_s[,c("high","low")], change = 10, percent = TRUE, retrace = FALSE, lastExtreme = TRUE)

# Pbands
FTAS_s$pbands <- PBands(FTAS_s$price)
BVSP_s$pbands <- PBands(BVSP_s$price)

# Lags
FTAS_s$lag <- lag(FTAS_s$price)
BVSP_s$lag <- lag(BVSP_s$price)

# Chaikin Volatility
FTAS_s$chvol <- chaikinVolatility(FTAS_s[,c("high","low")], n = 5)
BVSP_s$chvol <- chaikinVolatility(BVSP_s[,c("high","low")], n = 5)

# Disparity 5
FTAS_s$sma2 <- SMA(FTAS_s$price,n=2)
FTAS_s$disparityfive <- (FTAS_s$price- FTAS_s$sma2)/ (FTAS_s$sma2 *100)

BVSP_s$sma2 <- SMA(BVSP_s$price,n=2)
BVSP_s$disparityfive <- (BVSP_s$price- BVSP_s$sma2)/ (BVSP_s$sma2 *100)

# On Balance Volume (OBV)
FTAS_s$OBV <- OBV(FTAS_s$close, FTAS_s$logvolume)
BVSP_s$OBV <- OBV(BVSP_s$close, BVSP_s$logvolume)

# Money Flow Index
FTAS_s$MFI <- MFI(FTAS_s[,c("high","low", "close")], FTAS_s$logvolume, n=14)
BVSP_s$MFI <- MFI(BVSP_s[,c("high","low", "close")], BVSP_s$logvolume, n=14)

# Simple moving average
FTAS_s$sma5 <- SMA(FTAS_s$price, n=5)
FTAS_s$sma10 <- SMA(FTAS_s$price, n=10)
FTAS_s$sma20 <- SMA(FTAS_s$price, n=20)

BVSP_s$sma5 <- SMA(BVSP_s$price, n=5)
BVSP_s$sma10 <- SMA(BVSP_s$price, n=10)
BVSP_s$sma20 <- SMA(BVSP_s$price, n=20)

# Volume moving average
FTAS_s$volsma2 <- SMA(FTAS_s$logvolume,n=2)
FTAS_s$volsma5 <- SMA(FTAS_s$logvolume,n=5)
FTAS_s$volsma10 <- SMA(FTAS_s$logvolume,n=10)
FTAS_s$volsma10 <- SMA(FTAS_s$logvolume,n=20)

BVSP_s$volsma2 <- SMA(BVSP_s$logvolume,n=2)
BVSP_s$volsma5 <- SMA(BVSP_s$logvolume,n=5)
BVSP_s$volsma10 <- SMA(BVSP_s$logvolume,n=10)
BVSP_s$volsma10 <- SMA(BVSP_s$logvolume,n=20)

# Exponential moving average 
FTAS_s$ema2 <- EMA(FTAS_s$price,n=2)
FTAS_s$ema7 <- EMA(FTAS_s$price,n=7)
FTAS_s$ema14 <- EMA(FTAS_s$price,n=14)
FTAS_s$ema21 <- EMA(FTAS_s$price,n=21)

BVSP_s$ema2 <- EMA(BVSP_s$price,n=2)
BVSP_s$ema7 <- EMA(BVSP_s$price,n=7)
BVSP_s$ema14 <- EMA(BVSP_s$price,n=14)
BVSP_s$ema21 <- EMA(BVSP_s$price,n=21)

#Arms' Ease of Movement Value
FTAS_s$EMV <- EMV(FTAS_s[, c("high", "low")], FTAS_s$logvolume, n=14)
BVSP_s$EMV <- EMV(BVSP_s[, c("high", "low")], BVSP_s$logvolume, n=14)

#William's %R
FTAS_s$WPR <- WPR(FTAS_s[,c("high","low", "close")], n=14)
BVSP_s$WPR <- WPR(BVSP_s[,c("high","low", "close")], n=14)

# Keltner Channels
FTAS_s$keltnerChannels <- keltnerChannels(FTAS_s[,c("high","low", "close")], n=20)
BVSP_s$keltnerChannels <- keltnerChannels(BVSP_s[,c("high","low", "close")], n=20)

# Percent Rank over a Moving Window
FTAS_s$runPercentRank <- runPercentRank(FTAS_s$price, n = 14)
BVSP_s$runPercentRank <- runPercentRank(BVSP_s$price, n = 14)

# Compute Stochastic Oscillator
stoch_FTAS <- stoch(FTAS_s[, c("high", "low", "close")])
FTAS_s$stoch_k <- stoch_FTAS[, 1]
FTAS_s$stoch_d <- stoch_FTAS[, 2]

stoch_BVSP <- stoch(BVSP_s[, c("high", "low", "close")])
BVSP_s$stoch_k <- BVSP_s[, 1]
BVSP_s$stoch_d <- BVSP_s[, 2]

# Volatility
FTAS_s$volatility <- volatility(FTAS_s$price, n = 14)
BVSP_s$volatility <- volatility(BVSP_s$price, n = 14)

# Rate of Change (ROC)
FTAS_s$ROC <- ROC(FTAS_s$price)
BVSP_s$ROC <- ROC(BVSP_s$price)

# Momentum
FTAS_s$M2 <- momentum(FTAS_s$price, n=2)
FTAS_s$M7 <- momentum(FTAS_s$price, n=7)
FTAS_s$M14 = momentum(FTAS_s$price, n=14)
FTAS_s$M21 <-momentum(FTAS_s$price, n=21)

BVSP_s$M2 <- momentum(BVSP_s$price, n=2)
BVSP_s$M7 <- momentum(BVSP_s$price, n=7)
BVSP_s$M14 = momentum(BVSP_s$price, n=14)
BVSP_s$M21 <-momentum(BVSP_s$price, n=21)
head(FTAS_s)
#Brookman's genius indicator
FTAS_s$brookman <- (FTAS_s$intraday * FTAS_s$logvolume * FTAS_s$price) / exp(11)
BVSP_s$brookman <- (BVSP_s$intraday * BVSP_s$logvolume * BVSP_s$price) / exp(11)
## Combine technical and external indicators

external_indicators <- external_indicators %>% dplyr::select(-c(uk_carbon_price, `7day_elec_avg`, daily_elec_avg))
BVSP_s <- BVSP_s[, !is.na(names(BVSP_s))]
FTAS_s_combined <- merge(FTAS_s, external_indicators, by = "date", all.x = TRUE)
glimpse(FTAS_s_combined)

BVSP_s_combined <- merge(na.omit(BVSP_s), external_indicators, by = "date", all.x = TRUE)
glimpse(BVSP_s_combined)

FTAS_s <- FTAS_s %>% dplyr::select(-c(direction.1, direction))
BVSP_s <- BVSP_s %>% dplyr::select(-c(direction.1, direction))

FTAS_s_combined <-  FTAS_s_combined[!duplicated(FTAS_s_combined$date), ] 
BVSP_s_combined <-  BVSP_s_combined[!duplicated(BVSP_s_combined$date), ] 

for (i in colnames(FTAS_s)){
  if (is.numeric(FTAS_s[[i]])) {
    FTAS_s[[i]] <- scale(FTAS_s[[i]])
  }
}
for (i in colnames(BVSP_s)){
  if (is.numeric(BVSP_s[[i]])) {
    BVSP_s[[i]] <- scale(BVSP_s[[i]])
  }
}
for (i in colnames(FTAS_s_combined)){
  if (is.numeric(FTAS_s_combined[[i]])) {
    FTAS_s_combined[[i]] <- scale(FTAS_s_combined[[i]])
  }
}

for (i in colnames(BVSP_s_combined)){
  if (is.numeric(BVSP_s_combined[[i]])) {
    BVSP_s_combined[[i]] <- scale(BVSP_s_combined[[i]])
  }
}
```

# Introduction

In a widely cited article (Lo and MacKinlay, 1988) it was suggested that stock prices do not follow random walks, indicating that to some extent, stock markets are predictable. Many studies have subsequently attempted to predict stock index movements, with a large proportion of the research focussing on predicting the level of stock market return. However, predicting the direction of stock movement is also an important feature of an effective market trading strategy and may even be more profitable than trading based on level-based predictions with a certain forecast error (Leung et al., 2000).  

  

This aim of this paper is to provide a comparison of the performance of different predictive models using ensemble methods in a four-class classification task of the direction of intraday returns of stock market indices. A comparison will be made between predicting movements in indices from a developed and emerging economy by examining the performance in predicting the UK FTSE All-Share Index and the Brazilian Ibovespa (Bovespa) Index. The remainder of this paper is structured as follows. Section I reviews relevant literature around this topic. Section II gives a brief overview of the data used in this study. Section III presents the empirical approach and main results of the study and Section IV provides some extensions using alternative specifications. Finally, this paper summaries the results.  

  

 

# Section I: Literature review 

 

There are now many examples in the literature using different classification techniques to predict the direction of stock index movements. Much of the research considers a two-category classification problem, examining the performance of models in predicting upward or downward movements. One example is Shynkevich et al. (2017) who classify the movements in the closing price of the US S&P 500 stock market index into ‘Up’ or ‘Down’. Using a variety of classifiers, they find that Support Vector Machines (SVM) obtain the highest prediction accuracy of 75.4%. Lohrmann and Lukka (2019) demonstrate the value of using more event outcomes for classification in improving trading strategies. Using random forest classifiers to predict the intraday returns of the US S&P500 index, they consider a four-class classification problem: ‘strong positive’, ‘slightly positive’, ‘slightly negative’ and ‘strong negative’. They find that the accuracy of predictions for the four classes differed considerably. The models performed better in the classification of positive returns, with accuracy ranging between 40.7% (‘strong positive’) and 55.8% (‘slightly positive’), compared with negative returns, of which 23.8% (‘slightly negative’) to 41.2% (‘strong negative’) were correctly classified.   

  

As summarised in a review of more than 100 related articles, the sample size varies across studies, but many studies opt for a large amount of data to capture long run trends in the stock index (Atsalakis and Valavanis, 2009). A variety of features are used to support classification. These often include technical indicators, which are computed from historical financial data and are useful to identify future stock movements based on past behaviour, as well as external indicators, which allow researchers to capture market reactions to wider political and economic factors (Vargas et al, 2018). An estimated 20% of financial market forecasting approaches use technical indicators as input features (Atsalakis and Valavanis, 2009). These commonly include things like moving averages (MA), Bollinger Bands, and momentum indicators such as the relative strength index (RSI). O’Connor and Madden (2005) evaluate the effectiveness of using external indicators in addition to technical indicators as inputs in predicting movements in the Dow Jones Industrial Average Index, a price-weighted average of 30 major companies traded in the U.S. The addition of external indicators such as crude oil and exchange rate data was found to improve the predictive power and directional success of the models.   

  

In relation to UK stock indices, Leung et al. (2000) used a two-class classification problem (up or down) and various techniques such as binary choice models and artificial neural networks (ANN) to predict the movement of the UK FTSE 100 stock index returns. The highest accuracy achieved was 61%. Similar results were achieved in Brazil, though accuracy tends to be marginally lower. De Faria et al (2009) used ANN and adaptive exponential smoothing to estimate the direction of the Brazilian Ibovespa stock returns and found that the best models achieved an accuracy of around 60%. Fonseca et al (2021) predicted the directional movement of the stock return of 10 large companies in Brazil using SVM, which achieved an average accuracy of around 53%. There is limited evidence around the four-class classification of stock returns in these countries, which provides good motivation for this study.  

# Section II: Data summary 

The FTSE All-share index (FTAS) is a weighted index consisting of 600 of the largest companies listed on the London stock exchange. It serves as an excellent benchmark for UK stock price performance and the UK economy, capturing 98% of the UK’s market capitalization (LSEG, 2023.) Similarly, the Bovespa Index (BVSP) provides a representative performance measure of companies trading on the Brazilian ‘B3’ stock exchange. However, unlike the FTAS, the Bovespa Index exhibits significantly higher volatility, with a standard deviation of returns averaging 67.8% annually since 1968, compared to a mean return of 21.5% (Araújo, Brito and Sanvicente, 2020). This is likely due to both its smaller market capitalisation and macroeconomic instability. We believe this contrasts well with the FTAS and will provide different market dynamics on which to train our predictive models. 
  
Our datasets cover a period from the 1st of January 2023 to the 20th of March 2024, resulting in 301 and 306 observations of intraday returns for BVSP and FTAS, respectively. Price and volume data for all trading days were downloaded from Yahoo Finance. Initial time series price plots for the UK FTSE All-Share Index and the Brazilian Bovespa Index can be seen in Figure 1 and Figure 2 respectively.  

```{r FTSE Graphs, echo=FALSE}
BVSP_graph = ggplot(BVSP_s, aes(x = date, y = open)) +
    geom_line(color = "blue") +
    labs(x = "Date", y = "Price") +
    ggtitle("BVSP Price Over Time")

ggsave("bvsp_graph.png", plot = BVSP_graph, height = 6, width = 8, units = "in", dpi = 300)


# Time series plot for price_close over time for FTAS
ftas_graph = FTAS_graph = ggplot(FTAS_s, aes(x = date, y = close)) +
    geom_line(color = "blue") +
    labs(x = "Date", y = "Price") +
    ggtitle("FTAS Price Over Time")

ggsave("ftas_graph.png", plot = ftas_graph, height = 6, width = 8, units = "in", dpi = 300)
```

Over our sample period, FTAS and BVSP saw a 2.25% and 19.89% price increase, respectively. Despite this, the price moved up on only ~50% of days. 



When considering training the models using a larger time period, we were cautious about potential structural breaks caused by the COVID-19 pandemic. With data from 2023 onwards, we avoid overfitting to a trend that no longer exists. 

Aggarwal et al. (1999) studied 16 emerging and developed markets and found that the Ibovespa had the greatest volatility whilst the UK index had the lowest. In our data, returns for the Brazilian index range from -2.40% to +4.29% compared to -3.62% to +2.84% for FTAS. 
  
To predict intraday returns, we construct a feature set of technical trading indicators. We employ 42 indicators commonly used by other researchers (Atsalakis and Valavanis, 2009). These features transform price and volume data to provide information on trends, volatility and momentum - their lagged values may have some predictive power. Descriptions and formulas were taken from the R package, ‘TTR’.  A selected list is provided in Table 5.

In addition, following O’Connor and Madden (2005), we compile a dataset of relevant external indictors, which are presented in Table 6.

We normalize all numeric data to ensure that the models are scale invariant. Finally, we omit observations that contain missing values. These missing values occur due to some technical trading indicators requiring an initial number of days before producing a value.

# Section III: Empirical strategy and results 

## Empirical strategy

In order to predict intraday returns, we separate observations into four classes: ‘Large up’, ‘Small up’, ‘Large down’ and ‘Small down’ as in Lohrmann and Lukka (2019). 
  
We chose this criterion to have a sufficient sample size for each class. Since data is reported daily, we lead the intraday return variable so that the models can use only the previous days information to make a prediction. 
  
For each index, we train models using the following methods: 
  
Elastic Net – This regularization method penalizes higher magnitude coefficients. We tune the model using 8 different alphas and lambdas. The alpha hyperparameter determines the relative weights of the ridge and lasso penalties, whereas the lambda determines the penalty's strength. 
  
Decision Tree – This method works by repeatedly splitting the data into different subsets depending on a certain feature, until a specified stopping point. New data can then traverse the tree and be assigned a class. We tune the model by trying 8 different values of the complexity parameter, which represents a trade-off between incorporating information and computational cost. 
  
Random Forest – In a random forest, many trees are created – each using a different subset of features. New observations are tested on all trees and modal prediction is taken. For each tree we vary the number of features that can be used to construct it to introduce variation.  
  
Bootstrap Aggregating (Bagging) – Bagging is an ensemble method that creates many unpruned trees on different subsets of the data. The trees are then aggregated, reducing variance and making them robust to overfitting. This method can produce reliable predictions but is usually computationally expensive. 
  
Support Vector Machines (SVM) – SVM works to find the optimal decision boundary that separates the classes in a feature-dimensional space. 
  
For each model, we assess its performance using accuracy. We hypothesize that false positives and false negatives would be equally costly to a trader using our models, making accuracy suitable. 

Our primary results, shown in the subsequent section, use the dataset of technical trading indicators to forecast 1-step ahead. In the alternative specifications section, we combine both the technical and external indicators and assess the change in performance. Furthermore, we assess the feasibility of 5-step ahead forecasts. We also employ an alternative metric, Kappa in addition to accuracy. The kappa metric accounts for the fact that random guessing would produce correct predictions by chance. 

As an initial illustration, Figure 3 presents the variable importance plot (VIP) for the FTAS decision tree model with no external indicators. The Chaikin Money Flow (CMF) technical indicator, which measures the amount of money flowing into an asset over a period, is the most important variable for FTAS index prediction. The five most important variables are all technical indicators, as opposed to lagged values of the dependent variable, and this illustrates that these indicators contain some meaningful information.


```{r FTSE TTR setup, echo=FALSE}
##### Short term analysis from 2023 -------------------------------------------------------------------------------------

####Fixed Window forecasts 
### one-step- ahead
## Kappa Metric  

threshold_date <- as.Date("2023-01-01")

FTAS_s <- FTAS_s[FTAS_s$date >= threshold_date, ]



seeds <-vector(mode = "list", length = 63) # 32 +1 for  last model,
for(i in 1:62) seeds[[i]] =sample.int(1000, 8) # 8 = # of tuning parameter combinations

FTAS_s <- FTAS_s %>% na.omit()
## For the last model:
seeds[[63]] =sample.int(1000, 1)

library(doParallel)
registerDoParallel(cores=5)

myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = TRUE,
                             seeds = seeds)

tuneLength.num <-8  

```
# FTSE TTR 1 step fixed window
```{r FTSE TTR 1s, echo=FALSE}

glmnet.mod <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = FTAS_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = FTAS_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod

resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = FTAS_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = FTAS_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1
rf.mod1 <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1





resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


```
# FTSE TTR 5 step fixed window
```{r FTSE TTR fs, echo=FALSE}
### Five- step ahead forecast 

## Kappa Metric  


seeds[[63]] =sample.int(1000, 1)
myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 5, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = TRUE,
                             seeds = seeds)

tuneLength.num <-8  



glmnet.mod <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = FTAS_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod
vip(rpart.mod, num_features = 5)

rf.mod <-train(direction.2 ~ . - date,
               data = FTAS_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod




resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = FTAS_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = FTAS_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  

```
# FTSE TTR Non-fixed window 1 step
```{r FTSE TTR nf, echo=FALSE}
#### Non- fixed window forecast 

### one- step- head 

## Kappa Metric 


myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = FALSE,
                             allowParallel = FALSE,
                             seeds = seeds)


glmnet.mod <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = FTAS_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod
vip(rpart.mod, num_features = 5)

rf.mod <-train(direction.2 ~ . - date,
               data = FTAS_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = FTAS_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = FTAS_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1



resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


```
# FTSE TTR Non-fixed window 5 step
```{r FTSE TTR fs nf, echo=FALSE}
### Five- step ahead forecast 

## Kappa Metric  


myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 5, #The number of consecutive values in test set sample
                             fixedWindow = FALSE,
                             allowParallel = TRUE,
                             seeds = seeds)

tuneLength.num <-8  



glmnet.mod <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = FTAS_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = FTAS_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = FTAS_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = FTAS_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = FTAS_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = FTAS_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = FTAS_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


```
## FTSE external
```{r FTSE external 1s, echo=FALSE}
##### Using the external indicators------------------------------------------------------------------------

#### One- step ahead forecasts 
### Fixed Window 
## Kappa


FTAS_s_combined <- FTAS_s_combined %>% na.omit()
FTAS_s_combined <- FTAS_s_combined %>% dplyr::select(-c(direction.1, direction, nz_carbon_price, kor_carbon_price))

FTAS_s_combined <- FTAS_s_combined %>% rename(NGAS_price= `NGAS price`)

seeds <-vector(mode = "list", length = 316) # 32 +1 for  last model,
for(i in 1:315) seeds[[i]] =sample.int(1000, 8)

seeds[[316]] =sample.int(1000, 1)
myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = FALSE,
                             seeds = seeds)

tuneLength.num <-8  



glmnet.mod <-train(direction.2 ~ . - date,
                   data = FTAS_s_combined,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = FTAS_s_combined,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = FTAS_s_combined,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = FTAS_s_combined,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod



rf.mod <-train(direction.2 ~ . - date,
               data = FTAS_s_combined,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod



resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = FTAS_s_combined,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = FTAS_s_combined,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = FTAS_s_combined,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = FTAS_s_combined,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = FTAS_s_combined,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1




dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  

```
### FTSE external non-fixed window
```{r FTSE external nf w, echo=FALSE}
#### Non- fixed window forecast 

### one- step- head 

## Kappa Metric 


myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = FALSE,
                             allowParallel = TRUE,
                             seeds = seeds)


glmnet.mod <-train(direction.2 ~ . - date,
                   data = FTAS_s_combined,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = FTAS_s_combined,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = FTAS_s_combined,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = FTAS_s_combined,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = FTAS_s_combined,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = FTAS_s_combined,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = FTAS_s_combined,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = FTAS_s_combined,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = FTAS_s_combined,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = FTAS_s_combined,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  

```

## Brazil TTR 1 step fixed window
```{r Brazil TTR, echo=FALSE}
####Fixed Window forecasts 
### one-step- ahead
## Kappa Metric  

BVSP_s <- BVSP_s %>% na.omit

BVSP_s <- BVSP_s %>% dplyr::select(-c(`stoch_k`, `stoch_d`))
BVSP_s_combined <- BVSP_s_combined %>% dplyr::select(-c(`stoch_k`, `stoch_d`))

threshold_date <- as.Date("2023-01-01")

BVSP_s <- BVSP_s[BVSP_s$date >= threshold_date, ]

dim(BVSP_s)
BVSP_s <- BVSP_s %>% na.omit()

seeds <-vector(mode = "list", length = 95) # 32 +1 for  last model,
for(i in 1:94) seeds[[i]] =sample.int(1000, 8) # 8 = # of tuning parameter combinations

## For the last model:
seeds[[95]] =sample.int(1000, 1)
myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = FALSE,
                             seeds = seeds)

tuneLength.num <-8  




glmnet.mod <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = BVSP_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = BVSP_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = BVSP_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = BVSP_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


```
## Brazil TTR fixed five step
```{r Brazil TTR fs, echo=FALSE}
### Five- step ahead forecast 

## Kappa Metric  
seeds <-vector(mode = "list", length = 91)
for(i in 1:90) seeds[[i]] =sample.int(1000, 8)
seeds[[91]] =sample.int(1000, 1)
myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = FALSE,
                             seeds = seeds)

tuneLength.num <-8  

myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 5, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = TRUE,
                             seeds = seeds)

tuneLength.num <-8  



glmnet.mod <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = BVSP_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = BVSP_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = BVSP_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = BVSP_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


```
# Brazil TTR non-fixed window 1 step
```{r Brazil TTR nf w, echo=FALSE}
#### Non- fixed window forecast 

### one- step- head 

## Kappa Metric 
seeds <-vector(mode = "list", length = 95)
for(i in 1:94) seeds[[i]] =sample.int(1000, 8)
seeds[[95]] =sample.int(1000, 1)

myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = FALSE,
                             allowParallel = TRUE,
                             seeds = seeds)


glmnet.mod <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = BVSP_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = BVSP_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = BVSP_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = BVSP_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


```
## Brazil TTR non-fixed window 5 step

```{r Brazil TTR 5s nfnf, echo=FALSE}
### Five- step ahead forecast 

## Kappa Metric  
seeds <-vector(mode = "list", length = 91)
for(i in 1:90) seeds[[i]] =sample.int(1000, 8)
seeds[[91]] =sample.int(1000, 1)

myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 146,
                             horizon = 5, #The number of consecutive values in test set sample
                             fixedWindow = FALSE,
                             allowParallel = TRUE,
                             seeds = seeds)

tuneLength.num <-8  



glmnet.mod <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = BVSP_s,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = BVSP_s,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = BVSP_s,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = BVSP_s,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = BVSP_s,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = BVSP_s,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = BVSP_s,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  


``` 


# brazil external nf 
```{r Brazil external, echo=FALSE}
BVSP_s_combined <- BVSP_s_combined %>% na.omit()
BVSP_s_combined <- BVSP_s_combined %>% dplyr::select(-c(direction.1, direction, nz_carbon_price, kor_carbon_price))

BVSP_s_combined <- BVSP_s_combined %>% rename(NGAS_price= `NGAS price`)
BVSP_s_combined <- BVSP_s_combined[BVSP_s_combined$date >= threshold_date, ]
dim(BVSP_s_combined)

seeds <-vector(mode = "list", length = 29) # 32 +1 for  last model,
for(i in 1:28) seeds[[i]] =sample.int(1000, 8)

seeds[[29]] =sample.int(1000, 1)
myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 56,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = TRUE,
                             allowParallel = FALSE,
                             seeds = seeds)

tuneLength.num <-8  



glmnet.mod <-train(direction.2 ~ . - date,
                   data = BVSP_s_combined,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = BVSP_s_combined,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = BVSP_s_combined,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = BVSP_s_combined,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod



rf.mod <-train(direction.2 ~ . - date,
               data = BVSP_s_combined,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")                        


##Accuracy Metric 

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = BVSP_s_combined,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = BVSP_s_combined,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = BVSP_s_combined,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = BVSP_s_combined,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = BVSP_s_combined,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  

``` 
# Brazil TTR nf external 
```{r Brazil TTR nf external, echo=FALSE}
#### Non- fixed window forecast 

### one- step- head 

## Kappa Metric 


myTimeControl <-trainControl(method = "timeslice",
                             initialWindow = 56,
                             horizon = 1, #The number of consecutive values in test set sample
                             fixedWindow = FALSE,
                             allowParallel = TRUE,
                             seeds = seeds)


glmnet.mod <-train(direction.2 ~ . - date,
                   data = BVSP_s_combined,
                   method = "glmnet",
                   family = "multinomial",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Kappa')

glmnet.mod


bagging.mod <-train(direction.2 ~ . - date,
                    data = BVSP_s_combined,
                    method = "treebag",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Kappa')

bagging.mod


svm.mod <-train(direction.2 ~ . - date,
                data = BVSP_s_combined,
                method = "svmLinear",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Kappa')

svm.mod



rpart.mod <-train(direction.2 ~ . - date,
                  data = BVSP_s_combined,
                  method = "rpart",
                  trControl = myTimeControl,
                  tuneLength=tuneLength.num,
                  metric='Kappa')

rpart.mod


rf.mod <-train(direction.2 ~ . - date,
               data = BVSP_s_combined,
               method = "rf",
               family = "multinomial",
               trControl = myTimeControl,
               tuneLength=tuneLength.num,
               metric='Kappa')

rf.mod


resamps <-resamples(list(glmnet = glmnet.mod,
                         rpart=rpart.mod,
                         rf=rf.mod,
                         bagging=bagging.mod,
                         svm= svm.mod) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")


##Accuracy Metric

glmnet.mod1 <-train(direction.2 ~ . - date,
                    data = BVSP_s_combined,
                    method = "glmnet",
                    family = "multinomial",
                    trControl = myTimeControl,
                    tuneLength=tuneLength.num,
                    metric='Accuracy')

glmnet.mod1


bagging.mod1 <-train(direction.2 ~ . - date,
                     data = BVSP_s_combined,
                     method = "treebag",
                     family = "multinomial",
                     trControl = myTimeControl,
                     tuneLength=tuneLength.num,
                     metric='Accuracy')

bagging.mod1


svm.mod1 <-train(direction.2 ~ . - date,
                 data = BVSP_s_combined,
                 method = "svmLinear",
                 family = "multinomial",
                 trControl = myTimeControl,
                 tuneLength=tuneLength.num,
                 metric='Accuracy')

svm.mod1



rpart.mod1 <-train(direction.2 ~ . - date,
                   data = BVSP_s_combined,
                   method = "rpart",
                   trControl = myTimeControl,
                   tuneLength=tuneLength.num,
                   metric='Accuracy')

rpart.mod1

rf.mod1 <-train(direction.2 ~ . - date,
                data = BVSP_s_combined,
                method = "rf",
                family = "multinomial",
                trControl = myTimeControl,
                tuneLength=tuneLength.num,
                metric='Accuracy')

rf.mod1


resamps <-resamples(list(glmnet = glmnet.mod1,
                         rpart=rpart.mod1,
                         rf=rf.mod1,
                         bagging=bagging.mod1,
                         svm= svm.mod1) )
summary(resamps)

dotplot(resamps, metric = "Accuracy")
dotplot(resamps, metric = "Kappa")  

```

```{r VIP chart, echo=FALSE}
rpart.mod
vip(rpart.mod, num_features = 5)
```
## Results
 
We initially forecast one step ahead with rolling and recursive methods, for both UK and Brazilian markets. Recursive forecasts expand the in-sample window at each period, incorporating the newest information. Rolling forecasts keep the amount of data being used to forecast fixed, dropping the oldest observation in favour of the most recent. We begin with an initial window size of 146 observations and evaluate the one-step ahead forecasts with their accuracy metric.
 
Accuracy metrics are reported in Table 8 and box plots in Figures 4-7. The best models were rf – random forests – and glmnet – elastic net. These methods feature as the top 2 methods in all 4 uses. 

All models (aside from SVM FTAS recursive) perform better than random chance with a balanced classification data set, which in the four-class case is 25%. The highest accuracy achieved was 47% with the elastic net model and the models consistently performed better for the FTAS than for the BVSP. The best models for Brazil were elastic net and random forests which had a maximum average accuracy of 36%. The difference between the accuracies in the two markets aligns with what is seen in the literature, although it is more pronounced here. This difference could be because emerging markets are more exposed to economic shocks which makes the stock market harder to predict (Aggarwal et al., 1999). 

Our accuracy results for the FTAS are comparable with the average results of Lohrmann and Lukka (2019). Their four-class classification analysis of the S&P500 yielded average accuracy of 41.0-46.3% using random forests. Our results sit in the middle of their range at 44-45%. 

SVM consistently performs worst of any of the models we test, though it is notable that it performs relatively less poorly for the BVSP. However, this does differ from the apparent strength of SVM in Shynkeyich et al. (2017) who find SVM to be much stronger than alternative models. This is however, for a two-class problem, and for when the forecast horizon is equal to the input length, both features which are not aligned with our methodology, and could explain the differences observed.  Figures 4-7 show that the confidence intervals for models in most instances overlap, indicating that differences in terms of accuracy are not significant at the 95% confidence level.

# Section IV: Extended Analysis 

In an attempt to improve our predictions, we try both extending the forecast horizon and adding relevant external indicators. Again, both rolling and recursive forecasting are considered. We also consider an alternative metric – Kappa – to compare model performance. To exemplify why accuracy can be misleading, consider a data set where the majority of points fall into one category (e.g. small-down), a model that selects that category for all of its forecasts would attain a reasonable accuracy by chance without actually exploiting any of the patterns in the data. Kappa considers the correct predictions that will be achieved by chance and is therefore, more equipped to deal with these kinds of unbalanced data sets.  

When considering the accuracy metric, the extension of the forecast horizon to five steps ahead did not improve the model performance for either stock market index. The highest accuracy achieved for the FTAS Index at five-steps-ahead was 45%. This was achieved by both the bagging and the random forest models when performing recursive forecasting. In comparison, the one-step ahead elastic net recursive forecast achieved 47% accuracy. The highest accuracy for the BVSP Index at five-steps-ahead was the random forests recursive forecast at 35%. However, this model achieved 36% accuracy at one-step-ahead. Overall, at this longer horizon the recursive forecasting technique is favoured but the extension to five-steps ahead has offered no meaningful improvement to the predictive accuracy. 

For these recursive forecasting techniques, we now compare the models using the Kappa metric. The bagging model has the highest Kappa for five-step ahead predictions of the FTAS Index. However, Figure 8 shows that there is no significant difference between the Kappa metrics of the bagging, elastic net, decision tree or random forest models. The model performance comparison using the Kappa metric is in line with the results from the accuracy metric at the one-step ahead horizon, whereby the accuracy metric could not significantly distinguish between the top performing models and showed a relatively poorer performance of the SVM model. Figure 9 shows that for the BVSP Index, the bagging model has the highest Kappa. Again, there is not a significant difference between the Kappa metric of the best performing models and there is a relatively poor performance of SVM model. These results are also in line with the conclusions made using the BVSP index accuracy metrics for the one-step-ahead horizon. The inclusion of the Kappa metric has favoured the bagging models however, it has offered no further insight into a statistically significant top performing model. Overall, the alignment of the Kappa to the accuracy results assures us that our selection of optimal models was not the product of random chance predictions. 

We now consider the addition of external indicators to improve upon the one-step ahead recursive forecasting. From the VIP plot earlier, technical indicators provided valuable information. If, like these technical indicators, the external indicators include relevant information, they could improve the forecasting performance. However, their addition could hinder performance if they just introduce more noise into the data. Table 9 shows that for the FTAS index, the maximum accuracy achieved was by the elastic net model at 33%. This is considerably lower than the 47% accuracy achieved from the same model without the external variables. Table 10 shows that for the BVSP Index, 44% accuracy was achieved by the random forests model when external indicators are included. This is far greater than the 36% accuracy achieved by the same model without external indicators. This is despite having to use a shorter training period due to data availability. Therefore, these external indicators included some meaningful information that helped predict movements in the BVSP stock market index, whereas they were less helpful for the FTAS Index.

# Conclusion 

The aim of this paper was to provide a comparison of different models’ predictive abilities for a four-class classification task of the direction of intraday returns of stock market indices. The literature surveyed achieved predictive accuracies ranging from 20-60%. Thus, our highest accuracy of 47% for the FTSE index and 44% for the BVSP index is in line with the current predictive abilities within the literature. The relatively poorer forecasting performance of the emerging economy’s stock market index could be attributed to its volatile nature. Overall, for the Brazilian Index, the one-step ahead recursive random forest model with external indicators provided the best forecast accuracy. For the UK Index, the one-step ahead recursive elastic net model without external indictors provided the best forecast accuracy. Increasing the forecast horizon to 5-steps ahead did not improve the forecast accuracy and evaluation of the performance using the Kappa metric did not result in a statistically significant change in the optimal model. 

One possible limitation of our analysis is the relatively short time period considered, which was influenced by computational capability. Further research could explore whether predictive performance is improved with more observations. Additionally, an implicit assumption made in the analysis is that traders’ preferences towards positive and negative returns are balanced however, preferences between losses and gains may vary depending on individual trading strategies and attitudes to risk. Different performance metrics may therefore be more suitable depending on these individual characteristics. 
